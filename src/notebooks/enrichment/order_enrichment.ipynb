{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6318593e-a826-4039-8bbc-2ab113ba51fd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.widgets.text(\"start_version\", \"\", \"Manual Start Version (Backfill)\")\n",
    "dbutils.widgets.text(\"end_version\", \"\", \"Manual End Version\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b95c8752-95c3-4101-8e16-2be52979f8f0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6fbdcd80-9a50-4a84-9342-879574c92030",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pyspark.sql.functions as f\n",
    "from datetime import datetime\n",
    "sys.path.append(os.path.abspath('../..'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "327f27d9-d397-4f36-9edd-7f40bbba6ed8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from transformations.order_transforms import transform_orders, enrich_order_data\n",
    "from data_writers.write_data import upsert_delta_table\n",
    "from utils.transform_utils import normalize_raw_schema\n",
    "from utils.metadata_manager  import get_last_processed_version, update_last_processed_version, get_latest_table_version, get_pipeline_version_range\n",
    "from data_writers.maintenance import optimize_partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5c089cfe-6920-4b2b-b7ab-6be7b6a068a9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "start_val = dbutils.widgets.get(\"start_version\").strip()\n",
    "end_val = dbutils.widgets.get(\"end_version\").strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "96ffaee9-baf2-4877-bc92-72c9951c58eb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "CATALOG = \"pei\"\n",
    "SOURCE_SCHEMA = \"bronze\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ebf16798-f2ba-4968-92dd-283c411b7b9a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "raw_order_table_name = \"raw_orders\"\n",
    "enriched_order_table_name = \"orders_enriched\"\n",
    "quarantine_table_name = \"orders_quarantine\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "941ade10-f6c2-4ec5-8220-3442a43d163e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "try: \n",
    "    is_backfill = start_val.strip() != \"\"\n",
    "    \n",
    "    # get start and end versions for backfill or incremental processing\n",
    "    start_version, end_version = get_pipeline_version_range(\n",
    "    spark, CATALOG, SOURCE_SCHEMA, raw_order_table_name, start_val, end_val\n",
    "    )\n",
    "\n",
    "    if start_version > end_version:\n",
    "        raise Exception(f\"Invalid start and end versions. Start version: {start_version} is greater than end version: {end_version}.\")\n",
    "\n",
    "    df_raw_orders = (\n",
    "        spark.read.format(\"delta\")\n",
    "        .option(\"startingVersion\", start_version)\n",
    "        .option(\"endingVersion\", end_version)\n",
    "        .table(f\"{CATALOG}.{SOURCE_SCHEMA}.{raw_order_table_name}\")\n",
    "    )\n",
    "\n",
    "    # if changes, process them\n",
    "    if not df_raw_orders.isEmpty(): \n",
    "        df_normalized = normalize_raw_schema(df_raw_orders)\n",
    "        df_transformed = transform_orders(df_normalized)\n",
    "        df_validated = df_transformed.filter(~f.col(\"is_critical\"))\n",
    "\n",
    "        # contruct quarantine dataframe from valid dataframe\n",
    "        df_quarantine = (\n",
    "            df_validated\n",
    "            .filter(f.col(\"is_critical\") | f.col(\"is_warning\")) \n",
    "            .withColumn(\"severity_level\", f.when(f.col(\"is_critical\"), \"CRITICAL\").otherwise(\"WARNING\")) \n",
    "            .select(\"row_id\", \"quarantine_reason\", \"severity_level\", \"file_path\", \"ingestion_timestamp\", \"processing_timestamp\")\n",
    "        )\n",
    "\n",
    "        # write quarantine data for later analysis\n",
    "        if not df_quarantine.isEmpty(): \n",
    "            print(f\"Writing records to quarantine.\")\n",
    "            df_quarantine.write.format(\"delta\").mode(\"append\").saveAsTable(f\"{CATALOG}.silver.{quarantine_table_name}\")\n",
    "\n",
    "        df_prod = spark.read.table(f\"{CATALOG}.silver.products_enriched\").select(\"product_id\", \"category\", \"sub_category\")\n",
    "        df_cust = spark.read.table(f\"{CATALOG}.silver.customers_enriched\").select(\"customer_id\", \"customer_name\", \"country\")\n",
    "\n",
    "        # enrich orders data with customer and product details\n",
    "        df_enriched = enrich_order_data(df_validated, df_prod, df_cust)\n",
    "        df_unique = df_enriched.dropDuplicates([\"order_id\"])\n",
    "\n",
    "        # upsert to silver table\n",
    "        upsert_delta_table(\n",
    "            spark_session=spark,\n",
    "            df=df_unique,\n",
    "            target_table_name=f\"{CATALOG}.silver.{enriched_order_table_name}\",\n",
    "            join_key=\"order_id\",\n",
    "            partition_col=\"year_month\"\n",
    "        )\n",
    "\n",
    "        # Usually this will be part of the maintenance job.\n",
    "        #optimize_partitions(spark, \n",
    "        #                    f\"{CATALOG}.silver.{enriched_order_table_name}\", \n",
    "        #                    df_unique, \n",
    "        #                    \"year_month\", \n",
    "        #                    \"category,sub_category,customer_name\")\n",
    "\n",
    "        if not is_backfill:\n",
    "            # update version for incremental run\n",
    "            update_last_processed_version(spark, CATALOG, SOURCE_SCHEMA, raw_order_table_name, end_version)\n",
    "        \n",
    "        print(f\"Finished processing batch up to {end_version}\")\n",
    "    else: \n",
    "        print(\"No new data to process.\")\n",
    "except Exception as e: \n",
    "    print(f\"FAILED: Orders Enrichment. Error: {str(e)}\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "order_enrichment",
   "widgets": {
    "end_version": {
     "currentValue": "",
     "nuid": "413b6c5e-4d3a-42c0-bda6-ad7bf3f4600b",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "",
      "label": "Manual End Version",
      "name": "end_version",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "",
      "label": "Manual End Version",
      "name": "end_version",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    },
    "start_version": {
     "currentValue": "",
     "nuid": "9dfc8a7d-22b5-4f15-9109-21208d462654",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "",
      "label": "Manual Start Version (Backfill)",
      "name": "start_version",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "",
      "label": "Manual Start Version (Backfill)",
      "name": "start_version",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    }
   }
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
